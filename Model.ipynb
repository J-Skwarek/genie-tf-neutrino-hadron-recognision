{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d99fabf",
   "metadata": {},
   "source": [
    "3. Przygotowanie danych wejściowych do modelu i jego trening.\n",
    "\n",
    "Przygotowane zgodnie ze skryptem Zapis_danych.ipynb pliki `signal.csv` i `bgd.csv` zawierają obliczone wartości zmiennych kinematycznych dla każdego zdarzenia. Każdy wiersz zawiera parametry opisujące jedno zdarzenie. Usuwamy kolumnę `Typ`, a następnie rozdzielamy dane na zbiór treningowy i walidacyjny. Sieć uczymy na zbiorze treningowym zawierającym po 50 tysięcy zdarzeń tła oraz sygnału, reszta danych przechodzi do zbioru walidacyjnego. Liczby zdarzeń w plikach \"signal.csv\" oraz \"bgd.csv\" są dobrane tak, aby w zbiorze walidacyjnym otrzymać odpowiedni stosunek tła do sygnału"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Wczytaj dane\n",
    "signal_df = pd.read_csv(\"signal.csv\").drop(columns=[\"Typ\"])\n",
    "background_df = pd.read_csv(\"bgd.csv\").drop(columns=[\"Typ\"])\n",
    "\n",
    "X_signal = signal_df.to_numpy()\n",
    "X_background = background_df.to_numpy()\n",
    "\n",
    "# Podział na zbiór treningowy i walidacyjny. \n",
    "train_sig = X_signal[:50000]\n",
    "val_sig   = X_signal[50000:]\n",
    "train_bg  = X_background[:50000]\n",
    "val_bg    = X_background[50000:]\n",
    "# Tworzymy zbiór treningowy z przypadków sygnału oraz tła oraz wektory etykiet (klas) do treningu\n",
    "X_train = np.concatenate([train_sig, train_bg])\n",
    "y_train = np.concatenate([np.ones(len(train_sig)), np.zeros(len(train_bg))])\n",
    "# Analogicznie tworzymy zbiór z danymi do testowania modelu\n",
    "X_val = np.concatenate([val_sig, val_bg])\n",
    "y_val = np.concatenate([np.ones(len(val_sig)), np.zeros(len(val_bg))])\n",
    "\n",
    "# Konwertujemy wektory z etykietami do postaci wektorów z prawdopodobieństwem bycia daną klasą\n",
    "y_train_cat = to_categorical(y_train, num_classes=2)\n",
    "y_val_cat   = to_categorical(y_val, num_classes=2)\n",
    "\n",
    "print(\"=== Rozkład danych ===\")\n",
    "print(f\"Train sygnał: {np.sum(y_train==1)}\")\n",
    "print(f\"Train tło:    {np.sum(y_train==0)}\")\n",
    "print(f\"Val   sygnał: {np.sum(y_val==1)}\")\n",
    "print(f\"Val   tło:    {np.sum(y_val==0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b19014",
   "metadata": {},
   "source": [
    "=== Rozkład danych ===\n",
    "Train sygnał: 50000\n",
    "Train tło:    50000\n",
    "Val   sygnał: 9685\n",
    "Val   tło:    76092\n",
    "\n",
    "Używamy modelu opisanego w pracy. Parametr TRESHOLD ustawia próg prawdopodobieńśtwa od którego przypadek uznawany jest za sygnał. Na jego postawie wypisywana jest liczba przewidywanych klas przez model. Trenujemy pięć modeli i uśredniamy ich predykcje aby uzsykać lepszą statystykę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be7fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parametry modelu\n",
    "N_MODELS = 5\n",
    "THRESHOLD = 0.88\n",
    "sizes = [512, 256, 128]\n",
    "activation = \"relu\"\n",
    "\n",
    "input_shape = X_train.shape[1]\n",
    "\n",
    "def build_dnn_model(input_shape, sizes, act):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=(input_shape,)))\n",
    "    for size in sizes:\n",
    "        model.add(layers.Dense(size, activation=act))\n",
    "    model.add(layers.Dense(2, activation=\"softmax\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Trening kilku modeli i zapis predykcji walidacyjnych\n",
    "val_predictions_list = []\n",
    "\n",
    "for seed in range(N_MODELS):\n",
    "    print(f\"==> Trenuję model {seed+1}/{N_MODELS}...\")\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    model = build_dnn_model(input_shape, sizes, activation)\n",
    "    model.fit(X_train, y_train_cat, batch_size=50, epochs=10, validation_split=0.2, verbose=0)\n",
    "    \n",
    "    preds_val = model.predict(X_val, verbose=0)\n",
    "    val_predictions_list.append(preds_val)\n",
    "\n",
    "# Uśrednianie predykcji \n",
    "avg_val_preds = np.mean(val_predictions_list, axis=0)\n",
    "predicted_classes = (avg_val_preds[:, 1] > THRESHOLD).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3bbaa1",
   "metadata": {},
   "source": [
    "Dla wytrenowanego modelu możemy wypisać jego predykcje oraz otrzymane wartości czystości i efektywności."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_true = np.argmax(y_val_cat, axis=1)\n",
    "y_pred_classes = np.argmax(avg_val_preds, axis=1)\n",
    "\n",
    "print(\"\\n==> Metryki (średnia z predykcji wszystkich modeli):\")\n",
    "print(confusion_matrix(y_true, y_pred_classes))\n",
    "print(classification_report(y_true, y_pred_classes, digits=4))\n",
    "\n",
    "#  Statystyki predykcji \n",
    "unique, counts = np.unique(predicted_classes, return_counts=True)\n",
    "results_dict = dict(zip(unique, counts))\n",
    "\n",
    "print(\"\\n==> Przewidywana liczba przypadków:\")\n",
    "print(f\"  Tło (0): {results_dict.get(0, 0)}\")\n",
    "print(f\"  Sygnał (1): {results_dict.get(1, 0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48055d09",
   "metadata": {},
   "source": [
    "==> Metryki (średnia z predykcji wszystkich modeli):\n",
    "```\n",
    "[[58858 17234]\n",
    " [  882  8803]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0     0.9852    0.7735    0.8666     76092\n",
    "           1     0.3381    0.9089    0.4929      9685\n",
    "\n",
    "    accuracy                         0.7888     85777\n",
    "   macro avg     0.6617    0.8412    0.6797     85777\n",
    "weighted avg     0.9122    0.7888    0.8244     85777\n",
    "\n",
    "\n",
    "Przewidywana liczba przypadków:\n",
    "  Tło (0): 76175\n",
    "  Sygnał (1): 9602\n",
    "```\n",
    "\n",
    "\n",
    "  Następnie możemy narysować macierze klasyfikacji modelu oraz wykres czystości od efektywności."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73fb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Macierz klasyfikacji\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=[\"Tło (0)\", \"Sygnał (1)\"],\n",
    "            yticklabels=[\"Tło (0)\", \"Sygnał (1)\"])\n",
    "plt.xlabel(\"Przewidywana klasa\")\n",
    "plt.ylabel(\"Rzeczywista klasa\")\n",
    "plt.title(\"Macierz konfuzji \")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Rysujemy również macierz predykcji dla wybranej wartości pewności\n",
    "chosen_threshold = 0.88 \n",
    "y_pred_classes_treshold = (avg_val_preds[:, 1] > chosen_threshold).astype(int)\n",
    "cm_tresh = confusion_matrix(y_true, y_pred_classes_treshold)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm_tresh, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=[\"Tło (0)\", \"Sygnał (1)\"],\n",
    "            yticklabels=[\"Tło (0)\", \"Sygnał (1)\"])\n",
    "plt.xlabel(\"Przewidywana klasa\")\n",
    "plt.ylabel(\"Rzeczywista klasa\")\n",
    "plt.title(f\"Macierz konfuzji dla pewności: {chosen_threshold}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "probs = avg_val_preds[:, 1]\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_true, probs)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(recalls, precisions, color=\"red\", label=\"Model\")\n",
    "plt.xlabel(\"Efektywność \")\n",
    "plt.ylabel(\"Czystość \")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e91b7c7",
   "metadata": {},
   "source": [
    "![Macierz klasyfikacji](images/Macierz_konfuzji_walidacja.png)\n",
    "![Macierz klasyfikacji dla wybranej wartości pewności](images/Macierz_konfuzji_treshold.png)\n",
    "![Krzywa czystość-efektywność](images/PR_curve.png)\n",
    "\n",
    "Następnie możemy wyrysować jak wartości danego parametru wpływają na czystość oraz efektywność modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acb5e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def histograms(parameter, inputs, targets, predictions, purity_filename, efficiency_filename):\n",
    "    #Lista zmiennych\n",
    "    parameter_dict = {\n",
    "        'E_vis':    [0, 20, (1, 12), 'Energia widzialna [GeV]', 1], \n",
    "        'spheric':  [1, 20, (0, 1),   'Sferyczność', 1], \n",
    "        'pT':       [2, 20, (0, 1.5),  'Pęd poprzeczny [GeV]', 1], \n",
    "        'theta':    [3, 20, (0, 30), r'Kąt pędu całkowitego do osi $z$ [deg]', 1], \n",
    "        'pz':       [4, 20, (0, 10),'Pęd $p_z$ [GeV]', 1] \n",
    "    }\n",
    "\n",
    "    idx, hist_bins, hist_range, x_label, multiplier = parameter_dict[parameter]\n",
    "    # Przypisanie etykiet do zdarzeń\n",
    "    true_labels = np.argmax(targets, axis=1)  \n",
    "    # Podział na sygnał i tło\n",
    "    signal_indices = np.where(true_labels == 1)[0]\n",
    "    bg_indices = np.where(true_labels == 0)[0]\n",
    "    # Dane do histogramów\n",
    "    signal_hist_inputs = inputs[signal_indices, idx] * multiplier\n",
    "    bg_hist_inputs = inputs[bg_indices, idx] * multiplier\n",
    "\n",
    "    # True positives / false positives / false negatives\n",
    "    true_positives = signal_hist_inputs[predictions[signal_indices] == 1]\n",
    "    false_negatives = signal_hist_inputs[predictions[signal_indices] == 0]\n",
    "    false_positives = bg_hist_inputs[predictions[bg_indices] == 1]\n",
    "\n",
    "    # Histogramy liczności dla binów\n",
    "    true_hist, edges = np.histogram(true_positives, bins=hist_bins, range=hist_range)\n",
    "    false_pos_hist, _ = np.histogram(false_positives, bins=hist_bins, range=hist_range)\n",
    "    false_neg_hist, _ = np.histogram(false_negatives, bins=hist_bins, range=hist_range)\n",
    "    centers = (edges[:-1] + edges[1:]) / 2\n",
    "\n",
    "    # Liczenie czystości\n",
    "    purity = []\n",
    "    purity_error = []\n",
    "    for tp, fn in zip(true_hist, false_neg_hist):\n",
    "        denom = tp + fp\n",
    "        if denom > 0:\n",
    "            p = tp / denom\n",
    "            purity.append(p)\n",
    "            purity_error.append(np.sqrt(tp * (1 - p)) / denom)\n",
    "        else:\n",
    "            purity.append(np.nan)\n",
    "            purity_error.append(np.nan)\n",
    "\n",
    "    #  Liczenie efektywności\n",
    "    efficiency = []\n",
    "    efficiency_error = []\n",
    "    for tp, fp in zip(true_hist, false_pos_hist):\n",
    "        denom = tp + fn\n",
    "        if denom > 0:\n",
    "            e = tp / denom\n",
    "            efficiency.append(e)\n",
    "            efficiency_error.append(np.sqrt(tp * (1 - e)) / denom)\n",
    "        else:\n",
    "            efficiency.append(np.nan)\n",
    "            efficiency_error.append(np.nan)\n",
    "\n",
    "    # Rysowanie histogramu z czystością\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel(x_label, fontsize=15)\n",
    "    ax1.set_ylabel('N', color='tab:blue')\n",
    "    ax1.hist(bg_hist_inputs, density=True, bins=50, range=hist_range, alpha=0.6, label='Tło')\n",
    "    ax1.hist(signal_hist_inputs, density=True, bins=50, range=hist_range, alpha=0.6, label='Sygnał')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "    ax1.legend()\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Czystość', color='tab:red', fontsize=15)\n",
    "    ax2.errorbar(centers, purity, yerr=purity_error, linestyle='none', marker='o', color='tab:red', markersize=5)\n",
    "    ax2.set_ylim([0, 1.1])\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(purity_filename)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Rysowanie histogramu z efektywnością \n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel(x_label, fontsize=15)\n",
    "    ax1.set_ylabel('N', color='tab:blue')\n",
    "    ax1.hist(bg_hist_inputs, density=True, bins=50, range=hist_range, alpha=0.6, label='Tło')\n",
    "    ax1.hist(signal_hist_inputs, density=True, bins=50, range=hist_range, alpha=0.6, label='Sygnał')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "    ax1.legend()\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Efektywność', color='tab:red', fontsize=15)\n",
    "    ax2.errorbar(centers, efficiency, yerr=efficiency_error, linestyle='none', marker='o', color='tab:red', markersize=5)\n",
    "    ax2.set_ylim([0, 1.1])\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(efficiency_filename)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# Wywołanie histogramów  \n",
    "parameters = ['E_vis', 'pT', 'theta', 'pz', 'spheric']\n",
    "y_pred_custom_threshold = (avg_val_preds[:, 1] > THRESHOLD).astype(int)\n",
    "\n",
    "for param in parameters:\n",
    "    purity_file = f\"Czystosc_{param}.png\"\n",
    "    efficiency_file = f\"Efektywnosc_{param}.png\"\n",
    "    histograms(param, X_val, y_val_cat, y_pred_custom_threshold, purity_file, efficiency_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66d60f6",
   "metadata": {},
   "source": [
    "Wykresy zapisują się do plików o nazwie \"Czystosc/Efektywnosc_{nazwa parametru}.png\". Poniżej pokazano przykładowy narysowany histogram.\n",
    "\n",
    "![Czystosc_Evis.png](images/Czystosc_E_vis.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
