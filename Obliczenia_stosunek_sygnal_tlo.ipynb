{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802d9f5e",
   "metadata": {},
   "source": [
    "Kod używa wygenerowanych przekrojów czynnych oraz pliku zawierającego wiązkę strumienia neutrin do obliczenia przewidywanej liczby zdarzeń CC/NC dla neutrin danego zapachu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from typing import Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uproot\n",
    "\n",
    "#Stałe potrzebne do obliczeń\n",
    "NA = 6.02214076e23 #Liczba Avogadra\n",
    "M_mol_Ar = 39.948 #Masa molowa Argonu\n",
    "GeV_to_cm = 0.389379e-27 #Przelicza jednostki naturalne przekroju na cm^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a7999e",
   "metadata": {},
   "source": [
    "Najpierw przygotowano funkcje do wczytywania danych z pliku ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b70b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do pobierania poszczególnych histogramów z pliku ROOT\n",
    "def _root_get(obj, key: str):\n",
    "    if key in obj:\n",
    "        return obj[key]\n",
    "    if key.endswith(\";1\") and key[:-2] in obj:\n",
    "        return obj[key[:-2]]\n",
    "    alt = key + \";1\"\n",
    "    if alt in obj:\n",
    "        return obj[alt]\n",
    "    raise KeyError(f\"Brak obiektu '{key}' w pliku ROOT\")\n",
    "\n",
    "# FUnkcja do wczytywania histogramów fluxu neutrin z pliku ROOT. Zwraca środki binów energi oraz wartości fluxu w binie\n",
    "def load_flux_hist(root_path: str, hist_name: str,\n",
    "                   emin: Optional[float] = None, emax: Optional[float] = None\n",
    "                   ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "  \n",
    "    with uproot.open(root_path) as f:\n",
    "        h = _root_get(f, hist_name)\n",
    "        edges = h.axis().edges()             # krawędzie binów energii\n",
    "        vals = h.values(flow=False)          # wartości fluxu\n",
    "    centers = 0.5 * (edges[:-1] + edges[1:]) # środki binów\n",
    "\n",
    "    # przycięcie do zadanego zakresu energii\n",
    "    if emin is not None or emax is not None:\n",
    "        m = np.ones_like(centers, dtype=bool)\n",
    "        if emin is not None:\n",
    "            m &= (centers >= emin)\n",
    "        if emax is not None:\n",
    "            m &= (centers <= emax)\n",
    "        centers = centers[m]\n",
    "        vals = vals[m]\n",
    "    return centers, vals\n",
    "\n",
    "# Funkcja wczytująca wiele histogramów fluxów neutrin\n",
    "def load_fluxes(root_path: str, hist_map: Dict[str, str],\n",
    "                emin: Optional[float] = None, emax: Optional[float] = None\n",
    "                ) -> Dict[str, Tuple[np.ndarray, np.ndarray]]:\n",
    "    out = {}\n",
    "    for flv, hname in hist_map.items():\n",
    "        E, F = load_flux_hist(root_path, hname, emin=emin, emax=emax)\n",
    "        out[flv] = (E, F)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d740a837",
   "metadata": {},
   "source": [
    "Następnie przygotowano funkcje wczytujące przekroje czynne neutrin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b9ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Funkcja wczytuje pojedyńczy element w XML i wyciąga z niego przekrój oraz energię\n",
    "def _parse_knot_node(knot):\n",
    "    if \"E\" in knot.attrib and \"xsec\" in knot.attrib:\n",
    "        return float(knot.get(\"E\")), float(knot.get(\"xsec\"))\n",
    "    if \"x\" in knot.attrib and \"y\" in knot.attrib:\n",
    "        return float(knot.get(\"x\")), float(knot.get(\"y\"))\n",
    "    E_val, xs_val = None, None\n",
    "    for ch in knot:\n",
    "        tag = ch.tag.lower()\n",
    "        txt = (ch.text or \"\").strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        if tag == \"e\":\n",
    "            E_val = float(txt)\n",
    "        elif tag in (\"xsec\", \"xs\", \"y\"):\n",
    "            xs_val = float(txt)\n",
    "    if E_val is not None and xs_val is not None:\n",
    "        return E_val, xs_val\n",
    "    return None, None\n",
    "\n",
    "# Funkcja wczytuje cały plik XML i zwraca atrybuty: \"meta\" - nazwa procesu, E - tablica energii, xsec - tablica przekrojów\n",
    "def parse_genie_spline_xml(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    out = []\n",
    "    for spl in root.findall(\".//spline\"):\n",
    "        meta = spl.attrib.copy()\n",
    "        Es, Xs = [], []\n",
    "        for knot in spl.findall(\".//knot\"):\n",
    "            E, xs = _parse_knot_node(knot)\n",
    "            if E is not None:\n",
    "                Es.append(E)\n",
    "                Xs.append(xs)\n",
    "        if not Es:\n",
    "            E_flat = [float(ch.text) for ch in spl.findall(\".//E\") if ch.text and ch.text.strip()]\n",
    "            X_flat = [float(ch.text) for ch in spl.findall(\".//xsec\") if ch.text and ch.text.strip()]\n",
    "            if E_flat and X_flat:\n",
    "                n = min(len(E_flat), len(X_flat))\n",
    "                Es, Xs = E_flat[:n], X_flat[:n]\n",
    "\n",
    "        out.append({\"meta\": meta, \"E\": np.asarray(Es, float), \"xsec\": np.asarray(Xs, float)})\n",
    "    return out\n",
    "\n",
    "# Określa typ oddziaływania na podstawie nazwy procesu w pliku XML\n",
    "def _classify_current_from_name(name: str):\n",
    "    lo = name.lower()\n",
    "    if \"weak[cc+nc\" in lo: return \"BOTH\"\n",
    "    if \"weak[cc]\" in lo: return \"CC\"\n",
    "    if \"weak[nc]\" in lo: return \"NC\"\n",
    "    if \"proc:weak[cc\" in lo: return \"CC\"\n",
    "    if \"proc:weak[nc\" in lo: return \"NC\"\n",
    "    if \"cc]\" in lo and \"nc]\" not in lo: return \"CC\"\n",
    "    if \"nc]\" in lo and \"cc]\" not in lo: return \"NC\"\n",
    "    return None\n",
    "\n",
    "# Funkcja sumuje przekroje czynne podanej listy i zwraca wspólną tablice z energiami\n",
    "def _sum_terms(lst):\n",
    "    if not lst:\n",
    "        return np.array([]), np.array([])\n",
    "    E_union = np.unique(np.concatenate([d[\"E\"] for d in lst if d[\"E\"].size]))\n",
    "    xs_sum = np.zeros_like(E_union)\n",
    "    for d in lst:\n",
    "        if not d[\"E\"].size:\n",
    "            continue\n",
    "        xs_sum += np.interp(E_union, d[\"E\"], d[\"xsec\"], left=0.0, right=0.0)\n",
    "    return E_union, xs_sum\n",
    "\n",
    "# Funkcja ładuje przekroje czynne CC i NC z pliku XML i zwraca przeskalowane przekroje dla wszystkich energi\n",
    "def load_genie_total_cc_nc(xml_path, scale=1.0, require_one=True):\n",
    "    spl = parse_genie_spline_xml(xml_path)\n",
    "    cc_terms, nc_terms = [], []\n",
    "    for sp in spl:\n",
    "        name = sp[\"meta\"].get(\"name\", \"\")\n",
    "        cur = _classify_current_from_name(name)\n",
    "        if cur == \"CC\": cc_terms.append(sp)\n",
    "        elif cur == \"NC\": nc_terms.append(sp)\n",
    "        elif cur == \"BOTH\": cc_terms.append(sp); nc_terms.append(sp)\n",
    "    E_cc, xs_cc = _sum_terms(cc_terms)\n",
    "    E_nc, xs_nc = _sum_terms(nc_terms)\n",
    "    if require_one and (E_cc.size == 0 and E_nc.size == 0):\n",
    "        raise RuntimeError(f\"Nie znaleziono żadnego spline w {xml_path}\")\n",
    "    if E_cc.size and E_nc.size:\n",
    "        E_all = np.unique(np.concatenate([E_cc, E_nc]))\n",
    "    else:\n",
    "        E_all = E_cc if E_cc.size else E_nc\n",
    "    xs_cc_i = np.interp(E_all, E_cc, xs_cc, left=0, right=0) if E_cc.size else np.zeros_like(E_all)\n",
    "    xs_nc_i = np.interp(E_all, E_nc, xs_nc, left=0, right=0) if E_nc.size else np.zeros_like(E_all)\n",
    "    return E_all, xs_cc_i * scale, xs_nc_i * scale\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ae9384",
   "metadata": {},
   "source": [
    "\n",
    "Następnie zdefiniowano funkcję liczącą całke oraz liczącą liczby zdarzeń neutrinowych dla neutrin elektronowych, mionowych i taonowych.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d852b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Oblicza całke i liczbę zdarzeń dla neutrina danego zapachu\n",
    "def integrate_events(E: np.ndarray, flux: np.ndarray,\n",
    "                     xs_cc: np.ndarray, xs_nc: np.ndarray,\n",
    "                     pot: float, mass_kt: float,\n",
    "                     xs_units: str = \"cm2_per_nucleon\") -> Dict[str, float]:\n",
    " \n",
    "    if flux.shape != E.shape:\n",
    "        raise ValueError(\"Flux i E muszą mieć tę samą długość (po interpolacji).\")\n",
    "\n",
    "    # konwersja jednostek przekroju\n",
    "    xs_cc_m2 = xs_cc *GeV_to_cm * 1.0e-4\n",
    "    xs_nc_m2 = xs_nc *GeV_to_cm * 1.0e-4\n",
    "\n",
    "    # flux przeskalowany przez POT\n",
    "    flux_per_m2 = flux * pot\n",
    "\n",
    "    # Oblicza całki\n",
    "    cc = np.trapz(flux_per_m2 * xs_cc_m2, E) * mass_kt*NA*1e9/M_mol_Ar\n",
    "    nc = np.trapz(flux_per_m2 * xs_nc_m2, E) * mass_kt*NA*1e9/M_mol_Ar\n",
    "\n",
    "    return {\"CC\": cc, \"NC\": nc, \"TOT\": cc + nc}\n",
    "\n",
    "# Łączy poprzednio zdefiniowane funkcje i oblicza liczbe zdarzeń dla neutrin różnych zapachów\n",
    "def compute_counts(flux_root: str,\n",
    "                   flux_hists: Dict[str,str],\n",
    "                   xs_files: Dict[str,str],\n",
    "                   pot: float,\n",
    "                   mass_kt: float,\n",
    "                   emin: float,\n",
    "                   emax: float,\n",
    "                   xs_units: str = \"cm2_per_nucleon\") -> pd.DataFrame:\n",
    "    # Wczytanie strumienia neutrin\n",
    "    flux_cache = load_fluxes(flux_root, flux_hists, emin=emin, emax=emax)\n",
    "    # Wczytanie przekrojów czynnych\n",
    "    xs_cache = {}\n",
    "    for flv, path in xs_files.items():\n",
    "        if not pathlib.Path(path).exists():\n",
    "            raise FileNotFoundError(path)\n",
    "        xs_cache[flv] = load_genie_total_cc_nc(path, require_one=False)\n",
    "    # Obliczenia liczby zdarzeń dla każdego zapachu neutrina\n",
    "    rows=[]\n",
    "    for flv,(E_flux,F_flux) in flux_cache.items():\n",
    "        if flv not in xs_cache:\n",
    "            raise KeyError(f\"Brak XS dla smaku {flv}\")\n",
    "        E_xs, xs_cc, xs_nc = xs_cache[flv]\n",
    "        xs_cc_i = np.interp(E_flux, E_xs, xs_cc, left=0.0, right=0.0)\n",
    "        xs_nc_i = np.interp(E_flux, E_xs, xs_nc, left=0.0, right=0.0)\n",
    "        c = integrate_events(E_flux, F_flux, xs_cc_i, xs_nc_i, pot, mass_kt, xs_units=xs_units)\n",
    "        rows.append({\"flavor\":flv, **c})\n",
    "    df = pd.DataFrame(rows).set_index(\"flavor\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Wypisuje wyniki\n",
    "def print_report(df: pd.DataFrame) -> None:\n",
    "    with pd.option_context(\"display.float_format\",\"{:.3e}\".format):\n",
    "        print(\"\\n Liczby zdarzeń (CC, NC, TOT) \")\n",
    "        print(df)\n",
    "\n",
    "# Pliki potrzebne do analizy\n",
    "flux_root = \"g4lbne_FHC_FD.root\"\n",
    "flux_hists = {\"nue\": \"nue_fluxosc\", \"numu\": \"numu_fluxosc\", \"nutau\": \"nutau_fluxosc\"}\n",
    "xs_files = {\n",
    "    \"nue\": \"splines_3_04_02_nuE_Ar40_80.xml\",\n",
    "    \"numu\": \"splines_3_04_02_nuMu_Ar40_80.xml\",\n",
    "    \"nutau\": \"splines_3_04_02_nuTau_Ar40_80.xml\",\n",
    "}\n",
    "# Zakres energii dla których liczymy liczbę zdarzeń\n",
    "emin, emax = 0, 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdacd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wywołanie funkcji\n",
    "def main(argv=None):  \n",
    "    df = compute_counts(\n",
    "    flux_root=\"g4lbne_FHC_FD.root\",\n",
    "    flux_hists={\"nue\": \"nue_fluxosc\", \"numu\": \"numu_fluxosc\", \"nutau\": \"nutau_fluxosc\"},\n",
    "    xs_files={\n",
    "        \"nue\": \"splines_3_04_02_nuE_Ar40_80.xml\",\n",
    "        \"numu\": \"splines_3_04_02_nuMu_Ar40_80.xml\",\n",
    "        \"nutau\": \"splines_3_04_02_nuTau_Ar40_80.xml\"\n",
    "    },\n",
    "    pot=1.47e21,\n",
    "    mass_kt=40,\n",
    "    emin=0,\n",
    "    emax=20,\n",
    ")\n",
    "    print_report(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
